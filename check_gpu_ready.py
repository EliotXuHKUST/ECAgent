#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUç¯å¢ƒå°±ç»ªæ£€æŸ¥è„šæœ¬
éªŒè¯GPUè®­ç»ƒç¯å¢ƒæ˜¯å¦å®Œæ•´é…ç½®
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def check_basic_environment():
    """æ£€æŸ¥åŸºç¡€ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥åŸºç¡€ç¯å¢ƒ...")
    
    checks = {
        "Pythonç‰ˆæœ¬": sys.version_info >= (3, 8),
        "é¡¹ç›®æ ¹ç›®å½•": Path(".").exists(),
        "æ•°æ®ç›®å½•": Path("./data").exists() or True,  # å¯ä»¥åˆ›å»º
        "æ¨¡å‹ç›®å½•": Path("./models").exists() or True,  # å¯ä»¥åˆ›å»º
    }
    
    for check_name, result in checks.items():
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {check_name}")
    
    return all(checks.values())

def check_python_dependencies():
    """æ£€æŸ¥Pythonä¾èµ–"""
    print("\nğŸ“¦ æ£€æŸ¥Pythonä¾èµ–...")
    
    required_packages = {
        "torch": "PyTorch",
        "transformers": "Transformers",
        "peft": "PEFT (LoRAæ”¯æŒ)",
        "datasets": "Datasets",
        "bitsandbytes": "Bitsandbytes (é‡åŒ–æ”¯æŒ)",
        "accelerate": "Accelerate",
        "gradio": "Gradio (å‰ç«¯)",
        "fastapi": "FastAPI (åç«¯)",
        "psutil": "PSUtil (ç³»ç»Ÿç›‘æ§)"
    }
    
    missing_packages = []
    for package, description in required_packages.items():
        try:
            __import__(package)
            print(f"   âœ… {description}")
        except ImportError:
            print(f"   âŒ {description} - è¯·è¿è¡Œ: pip install {package}")
            missing_packages.append(package)
    
    return len(missing_packages) == 0

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print("\nğŸ–¥ï¸  æ£€æŸ¥GPUç¯å¢ƒ...")
    
    try:
        import torch
        
        # CUDAå¯ç”¨æ€§
        cuda_available = torch.cuda.is_available()
        print(f"   {'âœ…' if cuda_available else 'âŒ'} CUDAå¯ç”¨æ€§: {cuda_available}")
        
        if cuda_available:
            # GPUæ•°é‡
            gpu_count = torch.cuda.device_count()
            print(f"   âœ… GPUæ•°é‡: {gpu_count}")
            
            # GPUè¯¦æƒ…
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9
                print(f"   âœ… GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            
            # CUDAç‰ˆæœ¬
            cuda_version = torch.version.cuda
            print(f"   âœ… CUDAç‰ˆæœ¬: {cuda_version}")
            
            # æµ‹è¯•GPUæ“ä½œ
            try:
                test_tensor = torch.randn(10, 10).cuda()
                result = test_tensor @ test_tensor.T
                print(f"   âœ… GPUè®¡ç®—æµ‹è¯•: é€šè¿‡")
            except Exception as e:
                print(f"   âŒ GPUè®¡ç®—æµ‹è¯•: å¤±è´¥ - {e}")
                return False
        else:
            print("   âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        
        return True
        
    except ImportError:
        print("   âŒ PyTorchæœªå®‰è£…")
        return False

def check_project_files():
    """æ£€æŸ¥é¡¹ç›®æ–‡ä»¶"""
    print("\nğŸ“ æ£€æŸ¥é¡¹ç›®æ–‡ä»¶...")
    
    required_files = {
        "requirements.txt": "ä¾èµ–é…ç½®æ–‡ä»¶",
        "train_ecommerce_faq.py": "è®­ç»ƒä¸»è„šæœ¬",
        "models/fine_tuning/train.py": "å¾®è°ƒæ¨¡å—",
        "config/settings.py": "é…ç½®æ–‡ä»¶",
        "GPU_DEPLOYMENT_GUIDE.md": "GPUéƒ¨ç½²æŒ‡å—",
        "gpu_train.py": "GPUè®­ç»ƒè„šæœ¬",
        "monitor_gpu.py": "GPUç›‘æ§è„šæœ¬",
        "benchmark_gpu_model.py": "æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬"
    }
    
    missing_files = []
    for file_path, description in required_files.items():
        if Path(file_path).exists():
            print(f"   âœ… {description}")
        else:
            print(f"   âŒ {description} - æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            missing_files.append(file_path)
    
    return len(missing_files) == 0

def check_model_availability():
    """æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§"""
    print("\nğŸ¤– æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
    
    try:
        from transformers import AutoTokenizer
        
        # æµ‹è¯•åŸºç¡€æ¨¡å‹åŠ è½½
        model_name = "Qwen/Qwen-7B-Chat"
        print(f"   ğŸ” æµ‹è¯•æ¨¡å‹: {model_name}")
        
        try:
            tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
            print(f"   âœ… æ¨¡å‹tokenizeråŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"   âš ï¸  æ— æ³•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ (æ­£å¸¸ï¼Œé¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½): {e}")
            return True  # è¿™æ˜¯æ­£å¸¸çš„ï¼Œé¦–æ¬¡è¿è¡Œæ—¶æ¨¡å‹ä¼šè‡ªåŠ¨ä¸‹è½½
            
    except ImportError:
        print("   âŒ Transformersåº“æœªå®‰è£…")
        return False

def generate_quick_setup_guide():
    """ç”Ÿæˆå¿«é€Ÿè®¾ç½®æŒ‡å—"""
    print("\nğŸ“ å¿«é€Ÿè®¾ç½®æŒ‡å—:")
    print("=" * 50)
    
    print("\n1. å®‰è£…GPUç‰ˆPyTorch:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    
    print("\n2. å®‰è£…é¡¹ç›®ä¾èµ–:")
    print("   pip install -r requirements.txt")
    
    print("\n3. éªŒè¯GPUç¯å¢ƒ:")
    print("   python -c \"import torch; print(torch.cuda.is_available())\"")
    
    print("\n4. è¿è¡ŒGPUè®­ç»ƒ:")
    print("   python gpu_train.py")
    
    print("\n5. ç›‘æ§è®­ç»ƒè¿‡ç¨‹:")
    print("   python monitor_gpu.py")
    
    print("\n6. æ€§èƒ½åŸºå‡†æµ‹è¯•:")
    print("   python benchmark_gpu_model.py")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ECAgent GPUç¯å¢ƒå°±ç»ªæ£€æŸ¥")
    print("=" * 50)
    
    checks = [
        ("åŸºç¡€ç¯å¢ƒ", check_basic_environment),
        ("Pythonä¾èµ–", check_python_dependencies),
        ("GPUç¯å¢ƒ", check_gpu_environment),
        ("é¡¹ç›®æ–‡ä»¶", check_project_files),
        ("æ¨¡å‹å¯ç”¨æ€§", check_model_availability)
    ]
    
    all_passed = True
    for check_name, check_func in checks:
        try:
            result = check_func()
            if not result:
                all_passed = False
        except Exception as e:
            print(f"   âŒ {check_name}æ£€æŸ¥å¤±è´¥: {e}")
            all_passed = False
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼GPUç¯å¢ƒå·²å°±ç»ª")
        print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. è¿è¡Œ GPU è®­ç»ƒ: python gpu_train.py")
        print("2. å¯åŠ¨ç›‘æ§: python monitor_gpu.py --interval 5")
        print("3. æŸ¥çœ‹æŒ‡å—: cat GPU_DEPLOYMENT_GUIDE.md")
    else:
        print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        generate_quick_setup_guide()
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)